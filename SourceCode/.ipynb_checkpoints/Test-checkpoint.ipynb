{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IntegralImage as II\n",
    "from AdaBoost import StrongClassifier\n",
    "from Cascade import Cascade\n",
    "import Utils \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import partial\n",
    "import random\n",
    "import pickle\n",
    "import testAdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_feature_height = 2\n",
    "max_feature_height = 24\n",
    "min_feature_width = 2\n",
    "max_feature_width = 24\n",
    "train_path='../dataset/train/'\n",
    "validate_path ='../dataset/validate/'\n",
    "test_path='../dataset/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data and Pickle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npos_train_iis = [II.toIntegralImage(Utils.varianceNormalize(img)) for img in Utils.loadImages(train_path+\\'pos\\')]\\nneg_train_iis = [II.toIntegralImage(Utils.varianceNormalize(img)) for img in Utils.loadImages(train_path+\\'neg\\')]\\n\\npos_valid_iis = [II.toIntegralImage(Utils.varianceNormalize(img)) for img in Utils.loadImages(validate_path+\\'pos\\')]\\nneg_valid_iis = [II.toIntegralImage(Utils.varianceNormalize(img)) for img in Utils.loadImages(validate_path+\\'neg\\')]\\n\\npos_test_iis = [II.toIntegralImage(Utils.varianceNormalize(img)) for img in Utils.loadImages(test_path+\\'pos\\')]\\nneg_test_iis = [II.toIntegralImage(Utils.varianceNormalize(img)) for img in Utils.loadImages(test_path+\\'neg\\')]\\n\\nfiles = [open(\"../iis/pos_train_iis\",\\'wb\\'),open(\"../iis/neg_train_iis\",\\'wb\\')\\n         ,open(\"../iis/pos_valid_iis\",\\'wb\\'),open(\"../iis/neg_valid_iis\",\\'wb\\')\\n         ,open(\"../iis/pos_test_iis\",\\'wb\\'),open(\"../iis/neg_test_iis\",\\'wb\\')]\\n\\npickle.dump(pos_train_iis,files[0])\\npickle.dump(neg_train_iis,files[1])\\npickle.dump(pos_valid_iis,files[2])\\npickle.dump(neg_valid_iis,files[3])\\npickle.dump(pos_test_iis,files[4])\\npickle.dump(neg_test_iis,files[5])\\nfor f in files:\\n    f.close()\\n\\nprint(pos_train_iis[0])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pos_train_iis = [II.toIntegralImage(Utils.varianceNormalize(img)) for img in Utils.loadImages(train_path+'pos')]\n",
    "neg_train_iis = [II.toIntegralImage(Utils.varianceNormalize(img)) for img in Utils.loadImages(train_path+'neg')]\n",
    "\n",
    "pos_valid_iis = [II.toIntegralImage(Utils.varianceNormalize(img)) for img in Utils.loadImages(validate_path+'pos')]\n",
    "neg_valid_iis = [II.toIntegralImage(Utils.varianceNormalize(img)) for img in Utils.loadImages(validate_path+'neg')]\n",
    "\n",
    "pos_test_iis = [II.toIntegralImage(Utils.varianceNormalize(img)) for img in Utils.loadImages(test_path+'pos')]\n",
    "neg_test_iis = [II.toIntegralImage(Utils.varianceNormalize(img)) for img in Utils.loadImages(test_path+'neg')]\n",
    "\n",
    "files = [open(\"../iis/pos_train_iis\",'wb'),open(\"../iis/neg_train_iis\",'wb')\n",
    "         ,open(\"../iis/pos_valid_iis\",'wb'),open(\"../iis/neg_valid_iis\",'wb')\n",
    "         ,open(\"../iis/pos_test_iis\",'wb'),open(\"../iis/neg_test_iis\",'wb')]\n",
    "\n",
    "pickle.dump(pos_train_iis,files[0])\n",
    "pickle.dump(neg_train_iis,files[1])\n",
    "pickle.dump(pos_valid_iis,files[2])\n",
    "pickle.dump(neg_valid_iis,files[3])\n",
    "pickle.dump(pos_test_iis,files[4])\n",
    "pickle.dump(neg_test_iis,files[5])\n",
    "for f in files:\n",
    "    f.close()\n",
    "\n",
    "print(pos_train_iis[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [open(\"../iis/pos_train_iis\",'rb'),open(\"../iis/neg_train_iis\",'rb')\n",
    "         ,open(\"../iis/pos_valid_iis\",'rb'),open(\"../iis/neg_valid_iis\",'rb')\n",
    "         ,open(\"../iis/pos_test_iis\",'rb'),open(\"../iis/neg_test_iis\",'rb')]\n",
    "pos_train_iis=pickle.load(files[0])[0:1000]\n",
    "neg_train_iis=pickle.load(files[1])[0:1500]\n",
    "pos_valid_iis=pickle.load(files[2])\n",
    "neg_valid_iis=pickle.load(files[3])\n",
    "pos_test_iis =pickle.load(files[4])\n",
    "neg_test_iis =pickle.load(files[5])\n",
    "for f in files:\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train stage num 8\n",
      "To Achieve [3.50000000e-04 9.02605798e-01]\n",
      "Creating haar-like features..\n",
      "..done. 67608 features created.\n",
      "Calculating scores -> seletcting threshold -> getting votes for images..\n",
      "Calculating scores ...\n",
      "Features progress for calculationg score: 100%. Calculating scores Done\n",
      "\n",
      "Seletcting threshold ...\n",
      "Features progress for seletcting thresholds for each: 100%. Seletcting threshold  Done\n",
      "\n",
      "Getting features votes ...\n",
      "Features progress for Getting votes for each: 100%. Getting votes  Done\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      "N/A% (0 of 19) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting classifiers progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (19 of 19) |########################| Elapsed Time: 0:00:19 Time:  0:00:19\n",
      "N/A% (0 of 38) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print current cascsde fpr_dr[0.0006, 0.9200266577807398]\n",
      "Selecting classifiers progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (38 of 38) |########################| Elapsed Time: 0:00:38 Time:  0:00:38\n"
     ]
    }
   ],
   "source": [
    "# This will take a while\n",
    "cascade = Cascade(\"../Cascade/\")\n",
    "cascade.train(pos_train_iis,neg_train_iis,pos_valid_iis,neg_valid_iis,[.0001,.95],min_feature_width, max_feature_width, min_feature_height, max_feature_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "#testing adaboost\n",
    "classifier = testAdaBoost.StrongClassifier()\n",
    "classifier.initiateLearning(pos_train_iis,neg_train_iis,min_feature_width, max_feature_width, min_feature_height, max_feature_height)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = classifer.calcScoresStep1()\n",
    "'''\n",
    "f = open(\"./scores2\",'wb')\n",
    "pickle.dump(scores,f)\n",
    "f.close()\n",
    "scores = classifier.calcScoresStep1()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "f = open(\"./posScores/scores\",'wb')\n",
    "pickle.dump(scores[:,:len(pos_train_iis)],f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"./scores\",'rb')\n",
    "scores = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "classifier.optimizeParamsStep2(scores,len(pos_train_iis))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier.votes = classifier.calcVotesStep3(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier.selectClassifires(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing over 3233 faces:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC-PC\\Desktop\\facedetection\\SourceCode\\Cascade.py:96: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [fp*1./(len(iis)-num_pos),dr*1./num_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Detection Rate [nan, 0.928240024744819]%\n",
      "Testing over 10000 non faces:\n",
      "False Positive Rate [0.0118, nan]%\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing over {0} faces:\".format(len(pos_test_iis)))\n",
    "print(\"Face Detection Rate {0}%\".format(cascade.evaluate(pos_test_iis,len(pos_test_iis))))\n",
    "print(\"Testing over {0} non faces:\".format(len(neg_test_iis)))\n",
    "print(\"False Positive Rate {0}%\".format(cascade.evaluate(neg_test_iis,0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
